# Example configuration for Faker
---
name: "customer-support-dataset"
version: "1.0.0"
description: "A synthetic dataset of customer support conversations"
tags:
  - customer_support
  - synthetic_data
  - conversation

# LLM provider configuration
llm:
  provider: "gemini"
  model: "gemini-1.5-flash-002"
  project_id: "${PROJECT_ID}"         # Will be replaced with env var
  location: "${LOCATION}"             # Will be replaced with env var
  credentials_path: "${GOOGLE_APPLICATION_CREDENTIALS}"  # Service account credentials
  
  # Generation parameters (can be overridden in conversation section)
  temperature: 0.7
  top_p: 0.95
  top_k: 40
  max_tokens: 1024

# Dataset generation parameters
dataset:
  num_conversations: 5
  formats: ["split", "json", "jsonl"]  # List of output formats to generate
  output_dir: "${OUTPUT_DIR}"          # Will be replaced with env var

# Conversation parameters
conversation:
  roles:
    - user
    - support_agent
  min_messages: 4
  max_messages: 12
  domains:
    - tech_support
    - billing
    - account_issues
    - product_questions
    
  # Predefined speakers with custom IDs
  speakers:
    support_agents:
      - id: "agent_1"
        name: "David Lee"
        role: "support_agent"
        metadata: 
          experience: "senior"
          specialty: "technical issues"
      - id: "agent_2"
        name: "Rachel Green"
        role: "support_agent"
        metadata:
          experience: "mid-level"
          specialty: "billing inquiries"
    users:
      - id: "user_1"
        name: "Alex Thompson"
        role: "user"
        metadata:
          subscription: "premium"
          account_age: "2 years"
      - id: "user_2"
        name: "Jordan Smith"
        role: "user"
        metadata:
          subscription: "free"
          account_age: "6 months"
  
  # Generation approach parameters
  use_hybrid_approach: true       # Enable hybrid approach for better quality
  parallel_enhancement: true      # Enable parallel metadata enhancement
  max_parallel_enhancement: 5     # Maximum concurrent enhancement requests
  use_batch_requests: true        # Use batch requests for message enhancement
  batch_chunk_size: 10            # Number of messages to process in one batch
  
  # Rate limiting and performance parameters
  calls_per_minute: 60            # Maximum API calls per minute (rate limit)
  max_parallel_calls: 10          # Maximum parallel API calls allowed
  
  # Caching parameters
  use_cache: true                 # Enable response caching
  cache_size: 1000                # Maximum size of response cache
  
  # Generation parameters specific to conversations (overrides llm section)
  temperature: 0.8                # Higher temperature for more diverse outputs
  
  # Additional variables to use in templates
  variables:
    company_name: "TechCorp Inc."
    product_names: 
      - "CloudServer Pro"
      - "SecureVPN"
      - "DataSync"
      - "MobileGuard"
    customer_types:
      - "individual"
      - "small_business"
      - "enterprise"
    support_levels:
      - "tier_1"
      - "tier_2"
      - "tier_3"

# Prompt templates
templates:
  # System prompt to control generation (optional)
  system_prompt: |
    You are an expert in generating realistic conversational data for training AI systems.
    Your task is to create authentic-sounding conversations that include all the requested metadata.
    The content should be diverse but always professional and inoffensive.

  # Main conversation generation template
  conversation: |
    Generate a realistic customer support conversation between a customer and a support agent for {{company_name}}.
    
    Agent: {{agent_name}} ({{agent_id}})
    User: {{user_name}} ({{user_id}})
    Domain: {{domain}}
    Product: {{random(product_names)}}
    Customer Type: {{random(customer_types)}}
    Support Level: {{random(support_levels)}}
    
    The conversation should have between {{min_messages}} and {{max_messages}} total messages,
    and should represent a complete interaction with a clear issue and resolution.
    
    For each message, include the following metadata:
    - sentiment (positive, neutral, negative)
    - intent (e.g., greeting, question, clarification, solution, farewell)
    - entities (list of important named entities mentioned, like product names, technical terms)
    - topics (list of topics discussed in the message)
    - formality (formal, casual, technical)
    
    Format the output as a JSON array with the following structure:
    [
      {
        "role": "user",
        "content": "...",
        "sentiment": "...",
        "intent": "...",
        "entities": ["...", "..."],
        "topics": ["...", "..."],
        "formality": "..."
      },
      {
        "role": "support_agent",
        "content": "...",
        "sentiment": "...",
        "intent": "...",
        "entities": ["...", "..."],
        "topics": ["...", "..."],
        "formality": "..."
      },
      ...
    ]
    
    IMPORTANT: Use the agent and user names in the conversation. Make the conversation personalized
    for these specific individuals and refer to them by name occasionally in the messages.
  
  # Additional templates for generating personas
  user_persona: |
    Create a detailed persona for a customer contacting support at {{company_name}}.
    
    Include:
    - Age and demographic information
    - Technical proficiency level (beginner, intermediate, expert)
    - Communication style (formal, casual, frustrated, etc.)
    - Customer type: {{random(customer_types)}}
    - Background context that might be relevant
    - Reason for contacting support related to {{random(product_names)}}
    
    Format as a JSON object with appropriate fields.
  
  support_persona: |
    Create a detailed persona for a support agent at {{company_name}}.
    
    Include:
    - Experience level (junior, mid-level, senior)
    - Support level: {{random(support_levels)}}
    - Specialization areas related to {{random(product_names)}}
    - Communication style (formal, empathetic, technical, etc.)
    - Support approach and process
    - Background knowledge and training
    
    Format as a JSON object with appropriate fields.